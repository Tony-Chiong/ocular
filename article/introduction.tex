\section{Introduction}
% Relevance. What is the general motivation ---> What is the concrete problem.
The field of Brain-Computer Interfaces (BCI) has in the recent years been under active research, especially with the popularity of machine learning techniques. The reason for the interest, is the many useful application of a well-working BCI, such as replacing lost motor function in disabled people, helping with analysis in brain imaging to diagnose brain conditions or novel applications in computer games. 

The general idea of a BCI is to measure brain activity usually represented by electroencephalogram (EEG) signals, by putting sensors on the scalp, which can measure the electric impulses. Each sensor corresponds to a channel in the EEG data. However, the EEG data is noisy at best, and this problem can severely affect the results of classification algorithms. Therefore, signal processing for extracting important components of a signal or removal of artifacts, is an important step in any given BCI.

\cite{uriguen2015eeg} explain that non-physiological artifacts can usually be avoided or trivially removed. The physiological artifacts they have found to be most common are electrooculographic (EOG), electromyographic (EMG), and electrocardiographic (ECG) signals. They are also referred to as ocular, muscle, and cardiac artifacts respectively. Additionally, artifact removal can be done with or without a reference signal such as the EOG, and automatically or semi-automatically. Methods that do not need reference signals are more generally applicable, since reference signals are not always recorded and may be preferable not measure for the comfort of the subjects. 

%2. Explain the problem that you study — be clear, do not dive into unnecessary details.
This leaves us with several steps in which several techniques may be applied to obtain a corrected EEG signal and consequently obtain an accurate model that classifies the EEG data. Each technique applied may require several hyperparameters to be tuned for obtaining the optimal results, such as regularization parameters in machine learning algorithms. Such tuning is usually done manually, by experimenting with different values to see their effect on some validation data. Users of the BCI or medical professionals might be knowledgeable about tuning some of the parameters but not all, hence it requires either an expert to help determine them or extensive personnel training. Nonetheless, it requires a great deal of time for tuning the parameters, to obtain the best results. Another, more useful approach would be to automatically infer the hyperparameters from the training data. Such automatic parameter tuning have had positive results through Bayesian Optimization \citep{brochu2010tutorial,snoek2012practical,shahriari2016taking} which is an optimization technique that minimizes an unknown objective function by building a bayesian probabilistic model of the function, by treating the objective function as a black box.

%3  Describe your achievements — you can for example list them.
We propose a technique for correcting artifacts from EEG data based on the method by \citep{li2015ocular}. We adapt the technique for use in multi-class datasets by optimizing hyper-parameters for the artifact correction through Bayesian Optimization. This is different from the original approach, where parameters were either manually set or determined by binary logistic regression.

%4  Comment on related work — compare your approach with others; mention both the strengths and weaknesses.
\subsection{Related Work}
% Artifact Removal
Much research effort has been put into developing or applying techniques for artifact correction in EEG signals. Well-known methods such as \emph{Principal Component Analysis} (PCA), \emph{Independent Component Analysis} (ICA), and \emph{Wavelet Transform} (WT) have had mixed results in the research area \citep{uriguen2015eeg}. Both PCA and ICA are examples of \emph{Blind Source Separation} techniques. PCA is used to reduce the dimensionality of the data, and will return the principal components that maximizes variance of the data. ICA is a way of computing the independent components of a linear combined mixed source. WT can be used to decompose a signal into components describing the frequency over time of a signal. \cite{krishnaveni2006automatic} have used WT to automatically detect and remove ocular artifacts, but the efficiency of their method remains to be tested. 

Other approaches such as \emph{Eye Movement Correction Procedure} (EMCP) \citep{gratton1983new} utilises EOG signals measured from the eyes of the subject to detect ocular artifacts and then estimate a propagation factor that can be used to determine the amount of EOG to remove from the EEG signals. \cite{hoffmann2008correction} later did a review of EMCP and ICA, and found that even though these methods reduced the mutual information between the EOG and EEG signals, there were still residual artifacts present up to 250 ms afterwards. \cite{li2015ocular} have had positive results in estimating a pseudo-EOG signal for binary class EEG data, making it possible to obtain an artifact signal without using a reference signal as used in EMCP. Key benefits of this approach is that artifacts can be corrected from EEG signals alone which excludes the difficulty of handling the mutual effects between EEG and EOG signals.

% Feature extraction
The EEG measured on a channel forms a time series where the changes in amplitude over time contains the information that is sought to be classified. In order to reason about the data, this information must be extracted into features that can be used to train a classification algorithm. Application of ICA, PCA or DWT directly extract components that can be directly used as feature vectors. Another related techinque, is the \emph{Common Spatial Patterns} algorithm (CSP). CSP have been successful in extracting features that maximizes the potential for classification in EEG data \citep{ang2008filter,ang2012filter}.

% Classification of EEG
For classification of EEG feature vectors, several algorithms have been successful in achieving good results. The survey by \citet{chan2015systematic} on the performance of ensemble methods in EEG contexts argues that the classification algorithm Random Forests more accurately classifies EEG data than other well-known methods such as k nearest neighbors and Support Vector Machines. \citet{sun2007experimental} also surveys the effectiveness of ensemble methods, but argues that performance is subject to the choice of base classifier as weak learners. 

% Automatic parameter tuning
Several methods for (automatic) hyperparameter optimization exists such as grid search, random search, bayesian optimization and gradient-based hyperparameters optimization. Grid search is the most intuitive of the methods, but also the slowest since the approach is to evaluate all combinations of the parameters, which is very time consuming when dealing with multiple hyperparameters. Random search does not need to exhaustively try all combinations in search space, but starts at a random position in the search space and then evaluates new positions until some termination criterion is met. Bayesian optimization uses Gaussian processes to model an objective function with evaluations of the objective function as the posterior. The usefulness of Bayesian Optimzation is that it is possible to optimize over non-differentiable objective functions, as the objective function is treated as a black box. Gradient-based hyperparameter optimization uses Reverse-mode differentiation/backpropagation in order to estimate the gradient of function, which then is possible to optimize using gradient decent.
% Someone proposed to make several passes over eeg to remove a single type of artifact?

%5 Give an overview of the sections to follow
The paper is structured as follows. In \cref{sec:oacl} we explain the artifact correction scheme and how our adaptation differs from the original technique proposed by \citet{li2015ocular}. In \cref{sec:fbcsp} we discuss how to extract features from the corrected EEG time series by the filter-bank multi class Common Spatial Patterns algorithm. In \cref{sec:randomforest} we discuss classification of EEG features by the Random Forest classification algorithm. We then explain how we apply Bayesian Optimization to optimize hyperparameters in \cref{sec:bayesian-optimization}. Finally, we evaluate and discuss the results in \cref{sec:results}.
%\subsection{Overview}
%Ocular artifacts such as eye movements or blinking are often present in EEG data, and can be the cause for significant decrease in classification accuracy. The reason for this, is that the amplitude of a signal changes when eye movements happen and can introduce uncertainty about the information hidden in the signal that we are interested in classifying. In order to reduce the impact of these ocular artifacts, we use the OACL technique proposed by \citet{li2015ocular} and generalize it to handle multi-class EEG data. Additionally, we optimize the hyperparameters with Bayesian Optimization (BO). Our approach is illustrated in \cref{fig:ProgramPipeline}. The preprocessing steps consist of correcting artifacts from the data using OACL, then the corrected data is bandpass filtered to create a filterbank, each of the filters is then spatially filtered using CSP with a one-versus-rest approach, and then the spatially filtered data for each sub-band is classified.

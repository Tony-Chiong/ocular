\section{Introduction}
The field of Brain-Computer Interfaces (BCI) has in the recent years been under active research, especially with the popularity of machine learning techniques. The reason for the interest, is the many useful application of a well-working BCI, such as replacing lost motor function in disabled people, helping with analysis in brain imaging to diagnose brain conditions or novel applications in computer games. 

The general idea of a BCI is to measure brain activity usually represented by electroencephalogram (EEG) signals, by putting sensors on the scalp, which can measure the electric impulses. However, the EEG data is noisy at best, and this problem can severely affect the results of classification algorithms. Therefore, signal processing for extracting important components of a signal or removal of noise, is an important step in any given BCI.

\cite{uriguen2015eeg} explain that non-physiological artifacts can usually be avoided or trivially removed. The physiological artifacts they have found to be most common are electrooculographic (EOG), electromyographic (EMG), and electrocardiographic (ECG) signals. They are also referred to as ocular, muscle, and cardiac artifacts respectively. Additionally, artifact removal can be done with or without a reference signal, and automatically or semi-automatically. Methods that do not need reference signals are more generally applicable, since reference signals are not always recorded.

This leaves us with several steps in which several techniques may be applied to obtain a corrected EEG signal and consequently obtain a model that classifies the EEG data reasonably. Each technique applied may require several parameters to be tuned for obtaining the optimal results, such as the regularization parameter for a Support Vector Machine. Such tuning are usually done manually, by experimenting with different values to see their effect on some validation data. Users of the BCI or medical professionals might be knowledgeable about tuning some parameters but not all, hence it requires either an expert to help determine them or extensive training. Nonetheless, it requires a great deal of time for tuning the parameters, to obtain the best results.

Another, more useful approach would be to automatically infer the hyper-parameters from the training data. Recent work about algorithmically optimizing machine learning parameters has seen popularity by using \emph{Bayesian Optimization} \citep{brochu2010tutorial,snoek2012practical,shahriari2016taking}. Bayesian optimization maximizes an unknown objective function by building a model of the function by trying candidate samples as input to the objective function, and inferencing on the basis of outputs of experiments (see \cref{sec:bayesian-optimization}).

\subsection{Related Work}\todo{investigate if other ways of automatic parameter optimization exists}
Much research effort has been put into developing or applying techniques for noise/artifact correction in EEG signals. Well-known methods such as \emph{Principal Component Analysis}, \emph{Independent Component Analysis}, and \emph{Discrete Wavelet Transform} have had mixed results in the research area. Both PCA and ICA are examples of Blind Source Separation(BSS) techniques, PCA is used to reduce the dimensionality of the data, and will return the principal components that maximizes variance of the data. ICA is a way of computing the independent components of a linear combined mixed source. \todo{short description of DWT}   Most of these techniques considers how to extract the relevant information, instead of reducing the noise present.

Other approaches such as (EMCP/OACL) consider removing noise from a correction perspective. \cite{gratton1983new} uses EOG signals to detect when eye artifacts occur, and to estimate a propagation factor that can be used to determine the amount of EOG to remove from EEG. \cite{hoffmann2008correction} later did a review of EMCP and ICA, and found that even though these methods reduced the mutual information between the EOG and EEG signals, there were still residual artifacts present up to 250 ms afterwards. \cite{li2015ocular} have had positive results in estimating a pseudo-EOG signal for binary class EEG data, making it possible to obtain an artifact signal without using a reference signal. Key benefits of this approach is that noise can be corrected from EEG signals alone which excludes the difficulty of handling the mutual effects between EEG and EOG signals.

Common to most of the above mentioned methods is that they tend to use additional steps afterwards in the preprocessing step. These steps consisted of a bandpass filter of the EEG data, followed by an application of the \emph{Common Spatial Patterns} (CSP) algorithm \citep{ramoser2000optimal}. CSP computes spatial filters, which are used to project the data into a subspace which best discriminates the different classes. CSP is described in \cref{sec:csp}.
% Someone proposed to make several passes over eeg to remove a single type of artifact

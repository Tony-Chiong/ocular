\section{Filter Bank Common Spatial Patterns}
\todo{You should describe a bit more about Filter Bank and Multi Class CSP, at least 2 paragraphs for each technique.}
We have chosen to use a Filter bank multi class common spatial patterns (FBMCCSP) algorithm, for the purpose of extracting features from EEG data. The CSP algorithm has been used in many EEG classification studies within recent years, as in \cite{ang2012filter}. In all studies, CSP were considered a step of improvement to the classification of EEG classes. Based on these results, we chose to incorporate CSP as part of the classification pipeline. CSP assumes the user knows which frequency ranges contains important features for different imagery classes. Since one rarely knows of these ranges, we have implemented the filter bank algorithm, as a step before CSP, as this automatically chooses frequency ranges from EEG data. Filter bank is also a well studied algorithm, which is often used in conjunction with CSP, as in \cite{ang2008filter}. CSP can in its original form, only be used in binary classification problems, but the extension explained in this paper, multi class CSP (MCCSP), does not have that restriction. Since MCCSP makes use of the original binary CSP, we first explain how CSP works, and then extend it with multi class.

\begin {figure*}%[!hbtp]
\centering
\begin{adjustbox}{width=\textwidth}
\begin{tikzpicture}

% Variables
\pgfmathsetmacro{\bs}{0.5};
\pgfmathsetmacro{\boxl}{2};
\pgfmathsetmacro{\boxh}{1};
\pgfmathsetmacro{\ll}{1};
\coordinate (blength) at (0.5, 0);
\coordinate (linel) at (2, 0);
\coordinate (bh) at (0, 1);
\coordinate (bl) at (2, 0);
\newcommand*{\fblist}{-3, 0, 3}
\newcommand*{\csplist}{-1, 0, 1}
\def\filterbands{{"[4 - 8]","[8 - 12],"[12 - 16]"}}

% Coordinate for start circle
\coordinate (trains) at (0, 0);

% Coordinate for cross validation
\coordinate (crosss) at ($(trains) + (blength) + (linel) + 1/2*(bl)$);

% Coordinate for OACL
\coordinate (oacls) at ($(crosss) + (bl) + (linel)$);

% Coordinate for Filter Bank
\coordinate (filters) at ($(oacls) + (bl) + (linel)$);

% Coordinate for filterbank nodes
\coordinate (filterbanks) at ($(filters) + 1/2*(bl) + (linel) + 1/2*(blength)$);

% Coordinate for csp ovr nodes
\coordinate (cspovrs) at ($(filterbanks) + 1/2*(blength) + (linel)$);

% Coordinate for Feature selection nodes
\coordinate (featureselections) at ($(cspovrs) + 1/2*(blength) + 3/2*(linel)$);

% Coordinate for voting box
\coordinate (votings) at ($(featureselections) + 1/2*(blength) + 3/2*(linel) + 1/2*(bl)$);

% Coordinate for result node
\coordinate (results) at ($(votings) + 1/2*(bl) + 1/2*(blength) + (linel)$);

% Coordinate for mean results
\coordinate (meanresults) at ($(results) + (blength) + (linel)$);

% Cooordinates for start and end of step box
\coordinate (boxceil) at (0, 6);
\coordinate (boxfloor) at (0, -9);
\coordinate (startbox) at ($(trains) + (-1, 0)$);
\coordinate (endbox) at ($(meanresults) + (1, 0)$);


% Draw training data circle
\node [draw, circle, name=traincircle, minimum size = \bs] at (trains) {};

% Draw Cross validation box
\node (crossvalidation) at (crosss) [draw,thick,minimum width=\boxl cm,minimum height=\boxh cm] {Crossvalidation};
\draw [->] (traincircle) -- (crossvalidation);

% Draw oacl box
\node (oacl) at (oacls) [draw,thick,minimum width=\boxl cm,minimum height=\boxh cm] {Ocular Artifact Correction};
\draw [->] (crossvalidation) -- (oacl);

% Draw Filter Bank
\node (filterbank) at (filters) [draw,thick,minimum width=\boxl cm,minimum height=\boxh cm] {Filter Bank};
\draw [->] (oacl) -- (filterbank);

% Draw Filter Bank Nodes and CSP OVR nodes
\foreach \x in \fblist
	\foreach \y in \csplist{
		\node [draw, circle, name=filterbanknode\x, minimum size = \bs] at ($(filterbanks) + (0, \x)$) {};
		\draw [->] (filterbank) -- (filterbanknode\x);
		\node [draw, circle, name=cspovrnode\x\y, minimum size = \bs] at ($(filterbanknode\x) + (0, \y) + 3/2*(linel)$) {};
		\draw [->] (filterbanknode\x) -- (cspovrnode\x\y);
}

% Draw filter bands
\noindent\foreach [count=\i] \x in \fblist{
	\draw [->] (filterbank) -- node[above] {[$4*\i$ - 8]} (filterbanknode\x);
}


% Draw Feature selection nodes
\foreach \x in \fblist{
	\node [draw, circle, name=featurenode\x, minimum size = \bs] at ($(featureselections) + (0, \x) + 1/2*(linel)$) {};
			
}

% Draw feature selection arrows
\foreach \x in \fblist{
	\draw [->] (cspovrnode\x1) -- (featurenode3);
}
\foreach \x in \fblist{
	\draw [->] (cspovrnode\x0) -- (featurenode0);
}
\foreach \x in \fblist{
	\draw [->] (cspovrnode\x-1) -- (featurenode-3);
}

% Draw voting node and arrows
\node (votingbox) at (votings) [draw,thick,minimum width=\boxl cm,minimum height=\boxh cm] {Voting};
\foreach \x in \fblist{
	\draw [->] (featurenode\x) -- (votingbox);	
}

% Draw result node
\node [draw, circle, name=result, minimum size = \bs] at (results) {};
\draw [->] (votingbox) -- (result);

% Draw mean result node
\node [draw, circle, name=meanresult, minimum size = \bs] at (meanresults) {};
\draw [->] (result) -- (meanresult);

% Draw curved arrows
\draw [->] (result) to[out=280, in=270, distance=180] (crossvalidation);
\draw [->] (meanresult) to[out=270, in=270, distance=260] (crossvalidation);

% Draw box around image and horizontal lines
\draw ($(startbox) + (boxfloor)$) -- ($(endbox) + (boxfloor)$) -- ($(endbox) + (boxceil)$) -- ($(startbox) + (boxceil)$) -- cycle;

\draw[loosely dotted] ($(trains) + (boxfloor) + 1/2*(linel)$) -- ($(trains) + (boxceil) + 1/2*(linel)$);
\node[draw] at ($(trains) + (boxceil) - (0, 1)$) {1};

\draw[loosely dotted] ($(crosss) + (boxfloor) + (linel)$) -- ($(crosss) + (boxceil) + (linel)$);
\node[draw] at ($(crosss) + (boxceil) - (0, 1)$) {2};

\draw[loosely dotted] ($(oacls) + (boxfloor) + (linel)$) -- ($(oacls) + (boxceil) + (linel)$);
\node[draw] at ($(oacls) + (boxceil) - (0, 1)$) {3};

\draw[loosely dotted] ($(filters) + (boxfloor) + (linel)$) -- ($(filters) + (boxceil) + (linel)$);
\node[draw] at ($(filters) + (boxceil) - (0, 1)$) {4};

\draw[loosely dotted] ($(filters) + (boxfloor) + 9/4*(linel)$) -- ($(filters) + (boxceil) + 9/4*(linel)$);
\node[draw] at ($(filters) + (boxceil) - (0, 1) +7/4*(linel)$) {5};

\draw[loosely dotted] ($(filterbanks) + (boxfloor) + 9/4*(linel)$) -- ($(filterbanks) + (boxceil) + 9/4*(linel)$);
\node[draw] at ($(filterbanks) + (boxceil) - (0, 1) +3/2*(linel)$) {6};

\draw[loosely dotted] ($(featureselections) + (boxfloor) + (linel)$) -- ($(featureselections) + (boxceil) + (linel)$);
\node[draw] at ($(featureselections) + (boxceil) - (0, 1)$) {7};

\draw[loosely dotted] ($(votings) + (boxfloor) + (linel)$) -- ($(votings) + (boxceil) + (linel)$);
\node[draw] at ($(votings) + (boxceil) - (0, 1)$) {8};


\end{tikzpicture}
\end{adjustbox}
\caption{Overview of program pipeline}
\label{fig:ProgramPipeline}
\end{figure*}

\subsection{Common Spatial Patterns}\label{sec:csp}
CSP finds spatial filters, which when applied to signals, gives the maximal mutual information between these, with respect to signal variance. The method assumes there are classification information hidden within the variance between signals. Assuming we are classifying on motor imagery for different body parts, as we are in the training and evaluation data, this assumption can be justified \cite{blankertz2008optimizing}.
Formally CSP combines data trials with the same imagery task. Let $\pmb{A}$ and $\pmb{B}$ be matrices of combined trials for imagery task 1 and 2 respectively,

\begin{equation}
\label{eq:csp_data}
\pmb{A}, \mathbf{B} \in \mathbb{R}^{n*m}
\end{equation}
where $n$ and $m$ are the number of signals and samples respectively. CSP now calculates the covariance matrices for $\pmb{A}$ and $\pmb{B}$,

\begin{equation}
\label{eq:covariance_matrice}
\pmb{A_{cov}} = \frac{(\pmb{A} \cdot \overline{\pmb{A}})^\mathsf{T}  \cdot (\pmb{A} \cdot \overline{\pmb{A}})}{m - 1}
\end{equation}
where $m$ is the number of samples in $\pmb{A}$, and elements of $\overline{\pmb{A}}$ is defined as,

\begin{equation}
\label{eq:a_bar}
\pmb{\overline{A}_{ij}} = \frac{\pmb{A_{i,1}} + \pmb{A_{i,2}} + ... + \pmb{A_{i,m}}}{m}
\end{equation}

By applying simultaneous diagonalization between $\pmb{A_{cov}}$ and $\pmb{B_{cov}}$, we form the eigenvectors $\pmb{P}$, which will be the spatial filters for maximizing variance between class 1 and 2. $\pmb{P}$ is found when both of the following diagonalizations hold, 

\begin{equation}
\label{eq:diagonalization_A}
\pmb{P} \cdot \pmb{A_{cov}} \cdot \pmb{P} = \pmb{D}, \quad \pmb{P}, \pmb{D}, \pmb{A_{cov}} \in \mathbb{R}^{n*n}
\end{equation}

\begin{equation}
\label{eq:diagonalization_B}
\pmb{P} \cdot \pmb{B_{cov}} \cdot \pmb{P} = \pmb{I}, \quad \pmb{P}, \pmb{I}, \pmb{B_{cov}} \in \mathbb{R}^{n*n}
\end{equation}

The spatial filter will now correspond to the first row of $\pmb{P}$, such that $\pmb{\vec{w}} = \pmb{P}^\mathsf{T}_{1}$ 

$\pmb{P}$ can now be used as a linear transformation which when applied to EEG signals, maps these into a new space, where signal features are more discriminative. The drawback of CSP is that the method only works on 2 imagery classes, whereas many real world applications requires a greater number of classes, for the application to be useful. CSP also assumes we know in which frequency the important features of each imagery class is.

\subsection{Filter Bank}
We propose our solution to the CSP problem, which combines a filter-bank method, with a multi class (MC) CSP. CSP expects the user to know the frequency of importance for each imagery class. These frequencies are however seldom known beforehand. Our solution to this problem, introduces a step called filter-bank (FB), which splits the data into filters of different frequencies, which will all be used in the classification stage. By splitting the data, the user can ignore the CSP requirement of knowing the right frequencies, since all data will be used in the phase of classification. FB can be seen in \cref{fig:ProgramPipeline} as step 4. Filters are chosen within the frequency range of 4 to 40, which should assure all relevant data is taken into account.\todo{Indsæt kilde på dette - Emil} Individual filters are chosen with a span of $n \in \{3,..,8\}$. As an example, say we choose a span of $4$, then the following set $F$ of filters are created, $F \in \{[4, 8], [8, 16],...,[36, 40]\}$. Every filter will be used in the creation of CSP's, which will form the basis of feature creation.   

\subsection{Multi Class CSP}
We introduce MCCSP by the one versus rest (OVR) method. The method constructs one CSP per class, by choosing a class, and treating every other class as being the same. This way we get one CSP per imagery class, each constructed to create the maximum variance to all other classes. The method is depicted in \Cref{fig:ProgramPipeline} as step 6. The example figure shows a pipeline with 3 filter bands, and three classes, from which 9 CSP are created. EEG features can now be found, by applying the spatial filters from CSP, to EEG trials. Our approach is to apply each CSP, to every trial, and combine all of their respective feature vectors. As an example, say we have $m$ CSP, after applying OVR over all classes, for all bands. If now we apply one of the $m$ CSP to a single trial, we get a feature vector with $n$ components. By applying all CSP to the same trial, and combining their feature vectors, we get a trial with $n * m$ features. We apply this method on all trials in the dataset, from where $n * m$ features are found, for every trial. These can now be used to train a random forest classifier.     








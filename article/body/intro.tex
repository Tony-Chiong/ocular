\section{Overview}
\todo{Describe the pipeline and filterbank}
Ocular artifacts such as eye movements or blinking are often present in EEG data, and is the cause for significant decrease in classification accuracy. The reason for this, is that the amplitude of a signal changes when eye movements happen and can introduce uncertainty about the events we are interested in classifying, such as motor imagery. In order to reduce the impact of these ocular artifacts, we use the OACL technique proposed by \citet{li2015ocular} and generalize it to handle multi-class EEG data. Additionally, we optimize the hyperparameters with Bayesian Optimization (BO). Our approach is illustrated in \cref{fig:ProgramPipeline}. The preprocessing steps consist of correcting artifacts from the data using OACL, then the corrected data is bandpass filtered to create a filterbank, each of the filters is then spatially filtered using CSP with a one-versus-rest approach, and then the spatially filtered data for each sub-band is classified.

However, since EEG data is measured in the high dimensional space $\mathbb{R}^{c \times s}$ where $c$ is the number of channels and $s$ the number of samples measured on each channel, it is necessary to reduce the time series that samples in a channel represents to components representing the features. For this purpose, we use the popular \emph{Common Spatial Patterns} algorithm which constructs spatial filters from the dataset and projects the data into a subspace describing the features.

In order to evaluate the performance of the Ocular Artifact Correction method, we perform classification on the features computed by the CSP algorithm.

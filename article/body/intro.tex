\section{Overview}
\todo{Describe the pipeline and filterbank}
Ocular artifacts such as eye movements or blinking are often present in EEG data, and is the cause for significant decrease in classification accuracy. The reason for this, is that the amplitude of a signal changes when eye movements happen and can introduce uncertainty about the events we are interested in classifying, such as motor imagery. In order to reduce the impact of these ocular artifacts, we use the OACL technique proposed by \citet{li2015ocular} and generalize it to handle multi-class EEG data. Our approach is illustrated in \cref{fig:ProgramPipeline}, we have chosen to extend the approach described in \citet{li2015ocular} with a Bayesian Optimization(BO) step which seeks to find the best hyper-parameters. To ensure that the parameters are the best fit, we use a cross-validation scheme. The preprocessing steps that follows are we start by correcting artifacts from the data using OACL, then the corrected data is bandpass filtered to create a filterbank, each of the filterbanks are then spatially filtered using CSP with a one-versus-rest approach and then the spatially filtered data for each filterbank is classified.

However, since EEG data is measured in the high dimensional space $\mathbb{R}^{c \times s}$ where $c$ is the number of channels and $s$ the number of samples measured on each channel, it is necessary to reduce the time series that samples in a channel represents to components representing the features. For this purpose, we use the popular \emph{Common Spatial Patterns} algorithm which constructs spatial filters from the dataset and projects the data into a subspace describing the features.

In order to evaluate the performance of the Ocular Artifact Correction method, we perform classificiation on the features computed by the CSP algorithm.

\section{Overview}
\todo{Describe the pipeline and filterbank}
Ocular artifacts such as eye movements or blinking are often present in EEG data, and is the cause for significant decrease in classification accuracy. The reason for this, is that the amplitude of a signal changes when eye movements happen and can introduce uncertainty about the events we are interested in classifying, such as motor imagery. In order to reduce the impact of these ocular artifacts, we use the OACL technique proposed by \citet{li2015ocular} and generalize it to handle multi-class EEG data. Our approach is illustrated in \cref{fig:ProgramPipeline}.

However, since EEG data is measured in the high dimensional space $\mathbb{R}^{c \times s}$ where $c$ is the number of channels and $s$ the number of samples measured on each channel, it is necessary to reduce the time series that samples in a channel represents to components representing the features. For this purpose, we use the popular \emph{Common Spatial Patterns} algorithm which constructs spatial filters from the dataset and projects the data into a subspace describing the features.

In order to evaluate the performance of the Ocular Artifact Correction method, we perform classificiation on the features computed by the CSP algorithm.
